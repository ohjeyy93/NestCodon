{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from subprocess import check_output\n",
    "import csv\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create dummy file to write down all the strains\n",
    "file=\"testnew.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ls', '/home/momo/Desktop/CDC/MaRSnew/NeSTcodon/output/'], returncode=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## open the dummy file\n",
    "f = open(file, \"w\")\n",
    "subprocess.run(['ls', '/home/momo/Desktop/CDC/MaRSnew/NeSTcodon/output/'], stdout=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract all the strains from the bam file\n",
    "f = open(file, \"r\")\n",
    "file2=\"testnewrevised.txt\"\n",
    "f2 = open(file2, \"w\")\n",
    "for line in f:\n",
    "    #print(line.strip('\\n').split(\"_S\",1)[0])\n",
    "    if line.strip('\\n').split(\"_S\",1)[0] in [\"18HAxx00xs001PfF0510\",\"18HAxx00xs002PfF0510\",\"18HAxx00xs003PfF0510\",\"18HAxx00xs004PfF0510\",\"18HAxx00xs005PfF0510\",\"18HAxx00xs006PfF0510\",\"18HAxx00xs007PfF0510\",\"18HAxx00xs008PfF0510\"]:\n",
    "        #print((line.strip('\\n').split(\"_S\",1)[0]))\n",
    "        f2.write(line.strip('\\n').split(\"_S\",1)[0])\n",
    "        f2.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"codondepthnew.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(file, \"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a list of strains\n",
    "\n",
    "dictionary={}\n",
    "strainList=[]\n",
    "count=0\n",
    "for line in f2:\n",
    "    if line.strip('\\n').split(\"_S\",1)[0] in [\"18HAxx00xs001PfF0510\",\"18HAxx00xs002PfF0510\",\"18HAxx00xs003PfF0510\",\"18HAxx00xs004PfF0510\",\"18HAxx00xs005PfF0510\",\"18HAxx00xs006PfF0510\",\"18HAxx00xs007PfF0510\",\"18HAxx00xs008PfF0510\"]:\n",
    "        count+=1\n",
    "        strainList+=[\"codon\"+str(count)]\n",
    "        strainList+=[line.strip('\\n').split(\"_S\",1)[0]]\n",
    "        dictionary[line.strip('\\n').split(\"_S\",1)[0]]=line.strip('\\n')\n",
    "\n",
    "#print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## open csv file\n",
    "with open(filename, 'w') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "    csvwriter.writerow(strainList) \n",
    "    #csvwriter.writerows(rows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup initial count, depth, and codon\n",
    "countofnucleotide=0\n",
    "sumOfDepth=0\n",
    "currentCodon=\"\"\n",
    "currentcodonnum=1\n",
    "file3=\"textnew.txt\"\n",
    "k = open(file3, \"w\")\n",
    "\n",
    "f2 = open(file2, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create list of codon depth for each strains\n",
    "WholeCodonlist=[] ###codon list for whole strains\n",
    "Codonlistname=[]  ## name of strains \n",
    "Codonsamplenum=0  ## codons for different strains\n",
    "currentGeneList=[]\n",
    "CurrentCodonList=[]\n",
    "    \n",
    "for line in f2:\n",
    "    #print(line)\n",
    "    #print('/home/momo/Desktop/CDC/DhruviPatel-Haiti_Test_bam/Haiti_Test_bam/'+line.strip('\\n')+'/alignments/output_FM_SR_DD_RG.bam')\n",
    "    #out=check_output(['samtools', 'depth', '-a', '/home/momo/Desktop/CDC/DhruviPatel-Haiti_Test_bam/Haiti_Test_bam/'+line.strip('\\n')+'/alignments/output_FM_SR_DD_RG.bam'])\n",
    "    file3=line.strip('\\n')+\"textnew.txt\"\n",
    "    k = open(file3, \"w\")\n",
    "    ## run samtools to obtain depth of each nucleotide base\n",
    "    #print(line.strip('\\n').split(\"_S\",1)[0\n",
    "    #print(line)\n",
    "    if line.strip('\\n') in [\"18HAxx00xs001PfF0510\",\"18HAxx00xs002PfF0510\",\"18HAxx00xs003PfF0510\",\"18HAxx00xs004PfF0510\",\"18HAxx00xs005PfF0510\",\"18HAxx00xs006PfF0510\",\"18HAxx00xs007PfF0510\",\"18HAxx00xs008PfF0510\"]:\n",
    "        #print(\"working\")\n",
    "        #print(line.strip('\\n'))\n",
    "        subprocess.run(['samtools', 'depth', '-a', '/home/momo/Desktop/CDC/MaRSnew/NeSTcodon2/output/'+dictionary[line.strip('\\n')]+'/alignments/output_FM_SR_DD_RG.bam'], stdout=k)\n",
    "        k2 = open(file3, \"r\")\n",
    "        #print(k2)\n",
    "        countofnucleotide=0\n",
    "        sumOfDepth=0\n",
    "        currentCodon=\"\"\n",
    "        #CurrentCodonList=[]\n",
    "        #Codonsamplenum+=1\n",
    "        currentCodonPos=0\n",
    "        currentGene=line.strip('\\n')\n",
    "\n",
    "        ## sum the depth of nucleotide base untill 3 of them is covered for each codon\n",
    "        ## set up initial codon and codon position for the loop\n",
    "        for line in k2:\n",
    "            currentCodon=(line.split()[0])\n",
    "            currentCodonPos=int(line.split()[1])//3+1\n",
    "            sumOfDepth+=int((line.split()[2]))\n",
    "            break\n",
    "        ## update the codon position and depth\n",
    "        \n",
    "        for line in k2:\n",
    "            #print(line)\n",
    "            #line.split()[2]\n",
    "            if int(line.split()[1])%3>0:\n",
    "                ## operation for same codon\n",
    "                if currentCodonPos==int(line.split()[1])//3+1:\n",
    "                    currentCodon=(line.split()[0])\n",
    "                    sumOfDepth+=int(line.split()[2])\n",
    "                    #print(currentCodon, currentCodonPos)\n",
    "                elif currentCodonPos!=int(line.split()[1])//3+1:\n",
    "                    currentCodon=(line.split()[0])\n",
    "                    sumOfDepth=0\n",
    "                    sumOfDepth+=int(line.split()[2])\n",
    "                    currentCodonPos=int(line.split()[1])//3+1\n",
    "            elif int(line.split()[1])%3==0:\n",
    "                ## operation when codon is done\n",
    "                currentCodon=(line.split()[0])\n",
    "                #print(currentCodon)\n",
    "                sumOfDepth+=int(line.split()[2])\n",
    "                countofnucleotide=1\n",
    "                currentCodonPos=int(line.split()[1])//3\n",
    "                #testname=currentCodon+\"codon\"+str(currentCodonPos)\n",
    "                #print(testname)\n",
    "                if sumOfDepth!=0:\n",
    "                    Codonlistname+=[currentCodon+\"codon\"+str(currentCodonPos)]\n",
    "                    CurrentCodonList+=[sumOfDepth]\n",
    "                    currentGeneList+=[currentGene]\n",
    "                sumOfDepth=0\n",
    "                #print(currentCodon, currentCodonPos)\n",
    "        #print(Codonlistname)\n",
    "        #if Codonsamplenum==1:\n",
    "        #    ## operation for first strain\n",
    "        #    WholeCodonlist+=[Codonlistname]\n",
    "        #    WholeCodonlist+=[CurrentCodonList]\n",
    "        #else:\n",
    "            ## operation for next strain\n",
    "            #WholeCodonlist+=[Codonlistname]\n",
    "WholeCodonlist+=[Codonlistname]\n",
    "WholeCodonlist+=[CurrentCodonList]\n",
    "WholeCodonlist+=[currentGeneList]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "###TEST section\n",
    "#print(WholeCodonlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write all the codon and strain information to csv output file\n",
    "with open(filename, 'w') as csvfile: \n",
    "    csvwriter = csv.writer(csvfile) \n",
    "    csvwriter.writerow([\"CodonPos\", \"CodonCov\", \"CodonSample\"])\n",
    "    #print(np.transpose(WholeCodonlist))\n",
    "    #print(len(WholeCodonlist[0]))\n",
    "    #print(len(WholeCodonlist[1]))\n",
    "    #print(len(WholeCodonlist[15]))\n",
    "    #print(list(zip(*WholeCodonlist)))\n",
    "    #print(*zip(*WholeCodonlist))\n",
    "    #WholeCodonListTranspose=list(map(list, zip(*WholeCodonlist)))\n",
    "    #print(WholeCodonListTranspose)\n",
    "    #for list in np.transpose(WholeCodonlist):\n",
    "    #    print(list)\n",
    "    #    csvwriter.writerow(list)\n",
    "    #    break\n",
    "    csvwriter.writerows(list(itertools.zip_longest(*WholeCodonlist, fillvalue=\"\")))\n",
    "    #csvwriter.writerows((zip(*np.transpose(WholeCodonlist)))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
